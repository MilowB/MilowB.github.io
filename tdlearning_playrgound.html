<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<title>REINFORCEjs: Gridworld with Dynamic Programming</title>
	<meta name="description" content="">
	<meta name="author" content="">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- jquery and jqueryui -->
	<script src="assets/external/jquery-2.1.3.min.js"></script>
	<link href="assets/external/jquery-ui.min.css" rel="stylesheet">
	<script src="assets/external/jquery-ui.min.js"></script>

	<!-- bootstrap -->
	<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
	<link href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css" rel="stylesheet">


	<!-- d3js -->
	<script src="https://d3js.org/d3.v6.min.js"></script>
	<!-- markdown -->
	<script type="text/javascript" src="assets/external/marked.js"></script>
	<script type="text/javascript" src="assets/external/highlight.pack.js"></script>
	<link rel="stylesheet" href="assets/external/highlight_default.css">
	<script>hljs.initHighlightingOnLoad();</script>

	<!-- mathjax : nvm now loading dynamically
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
-->

	<!-- rljs -->
	<script type="text/javascript" src="assets/lib/rl.js"></script>

	<!-- flotjs -->
	<script src="assets/external/jquery.flot.min.js"></script>

	<!-- mathjax -->
	<script>
		window.MathJax = {
			tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
			svg: { fontCache: 'global' }
		};
	</script>
	<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>

	<style>
		#wrap {
			width: 1000px;
			margin-left: auto;
			margin-right: auto;
		}

		body {
			font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
		}

		#draw {
			margin-left: 100px;
		}

		#exp {
			margin-top: 20px;
			font-size: 16px;
		}

		h2 {
			text-align: center;
			font-size: 30px;
		}

		svg {
			cursor: pointer;
		}
	</style>

	<script type="application/javascript">

		// Gridworld
		var Gridworld = function () {
			this.Rarr = null; // reward array
			this.T = null; // cell types, 0 = normal, 1 = cliff
			this.reset()
		}
		Gridworld.prototype = {
			reset: function () {

				// hardcoding one gridworld for now
				this.gh = 5;
				this.gw = 5;
				this.gs = this.gh * this.gw; // number of states
				this.finalState = 24;
				this.minReward = 0;
				this.maxReward = 0;
				// specify some rewards
				var Rarr = R.zeros(this.gs);
				var T = R.zeros(this.gs);
				Rarr[this.finalState] = 1.5;
				Rarr[7] = -0.5;

				T[2] = 1;
				T[12] = 1;
				T[22] = 1;

				this.Rarr = Rarr;
				this.T = T;
			},
			reward: function (s, a, ns) {
				// reward of being in s, taking action a, and ending up in ns
				return this.Rarr[s];
			},
			nextStateDistribution: function (s, a) {
				// given (s,a) return distribution over s' (in sparse form)
				if (this.T[s] === 1) {
					// cliff! oh no!
					// var ns = 0; // reset to state zero (start)
				} else if (s === this.finalState) {
					// agent wins! teleport to start
					var ns = this.startState();
					while (this.T[ns] === 1) {
						var ns = this.randomState();
					}
				} else {
					// ordinary space
					var nx, ny;
					var x = this.stox(s);
					var y = this.stoy(s);
					if (a === 0) { nx = x - 1; ny = y; }
					if (a === 1) { nx = x; ny = y - 1; }
					if (a === 2) { nx = x; ny = y + 1; }
					if (a === 3) { nx = x + 1; ny = y; }
					var ns = nx * this.gh + ny;
					if (this.T[ns] === 1) {
						// actually never mind, this is a wall. reset the agent
						var ns = s;
					}
				}
				// gridworld is deterministic, so return only a single next state
				return ns;
			},
			updateRewards: function () {
				for (var s = 0; s < this.Rarr.length; s++) {
					if (this.Rarr[s] > this.maxReward) {
						this.maxReward = this.Rarr[s];
					}
					if (this.Rarr[s] < this.minReward) {
						this.minReward = this.Rarr[s];
					}
				}
				minRew = this.minReward;
				maxRew = this.maxReward;
			},
			sampleNextState: function (s, a) {
				// gridworld is deterministic, so this is easy
				var ns = this.nextStateDistribution(s, a);
				var r = this.Rarr[ns]; // observe the raw reward of being in s, taking a, and ending up in ns
				r -= 0.01; // every step takes a bit of negative reward
				var out = { 'ns': ns, 'r': r };
				if (s === this.finalState && ns === 0) {
					// episode is over
					out.reset_episode = true;
				}
				return out;
			},
			allowedActions: function (s) {
				var x = this.stox(s);
				var y = this.stoy(s);
				var as = [];
				if (x > 0) { as.push(0); }
				if (y > 0) { as.push(1); }
				if (y < this.gh - 1) { as.push(2); }
				if (x < this.gw - 1) { as.push(3); }
				return as;
			},
			randomState: function () { return Math.floor(Math.random() * this.gs); },
			startState: function () { return 0; },
			getNumStates: function () { return this.gs; },
			getMaxNumActions: function () { return 4; },

			// private functions
			stox: function (s) { return Math.floor(s / this.gh); },
			stoy: function (s) { return s % this.gh; },
			xytos: function (x, y) { return x * this.gh + y; },
		}

		// ------
		// UI
		// ------
		var rs = {};
		var trs = {};
		var tvs = {};
		var pas = {};
		var previousObs = undefined;
		var cs = 60;  // cell size
		var barchart = false;
		var selectedCell = -1;
		var spec = {};
		spec["gamma"] = 0.9; // discount factor, [0, 1)
		spec["epsilon"] = 0.2; // initial epsilon for epsilon-greedy policy, [0, 1)
		spec["alpha"] = 0.1; // value function learning rate
		spec["lambda"] = 0; // eligibility trace decay, [0,1). 0 = no eligibility traces
		spec["beta"] = 0.1; // learning rate for smooth policy update
		var currentQvalue = 0;
		var currentAction = 0;
		var nextStateReward = 0;
		var nextBestActionQvalue = 0;
		var equation = false;

		var initGrid = function () {
			$(".qvaluescharts").hide();
			$("#rewardui").hide();
			var d3elt = d3.select('#draw');
			d3elt.html('');
			rs = {};
			trs = {};
			tvs = {};
			pas = {};

			var gh = env.gh; // height in cells
			var gw = env.gw; // width in cells
			var gs = env.gs; // total number of cells

			var w = 600;
			var h = 300;
			svg = d3elt.append('svg').attr('width', w).attr('height', h)
				.append('g').attr('transform', 'scale(1)');

			// define a marker for drawing arrowheads
			svg.append("defs").append("marker")
				.attr("id", "arrowhead")
				.attr("refX", 3)
				.attr("refY", 2)
				.attr("markerWidth", 3)
				.attr("markerHeight", 4)
				.attr("orient", "auto")
				.append("path")
				.attr("d", "M 0,0 V 4 L3,2 Z");

			for (var y = 0; y < gh; y++) {
				for (var x = 0; x < gw; x++) {
					var xcoord = x * cs;
					var ycoord = y * cs;
					var s = env.xytos(x, y);

					var g = svg.append('g');
					// click callbackfor group
					g.on('click', function (ss) {
						return function () { cellClicked(ss); } // close over s
					}(s));

					// set up cell rectangles
					var r = g.append('rect')
						.attr('x', xcoord)
						.attr('y', ycoord)
						.attr('height', cs)
						.attr('width', cs)
						.attr('fill', '#86847A')
						.attr('stroke', '#DEDEDE')
						.attr('stroke-width', 2);
					rs[s] = r;

					// reward text
					var tr = g.append('text')
						.attr('x', xcoord + 5)
						.attr('y', ycoord + 55)
						.attr('font-size', 10)
						.text('');
					trs[s] = tr;

					// skip rest for cliffs
					if (env.T[s] === 1) { continue; }

					// value text
					var tv = g.append('text')
						.attr('x', xcoord + 5)
						.attr('y', ycoord + 20)
						.text('');
					tvs[s] = tv;

					// policy arrows
					pas[s] = []
					for (var a = 0; a < 4; a++) {
						var pa = g.append('line')
							.attr('x1', xcoord)
							.attr('y1', ycoord)
							.attr('x2', xcoord)
							.attr('y2', ycoord)
							.attr('stroke', 'black')
							.attr('stroke-width', '2')
							.attr("marker-end", "url(#arrowhead)");
						pas[s].push(pa);
					}
				}
			}

			// append agent position circle
			svg.append('circle')
				.attr('cx', -100)
				.attr('cy', -100)
				.attr('r', 15)
				.attr('fill', '#327BB5')
				.attr('stroke', '#000')
				.attr('id', 'cpos');

		}

		function showBarChart(actionValues, svg, gridSize) {
			if (barchart) {
				var chartWidth = 200;  // Largeur de la zone du bar chart
				var chartHeight = gridSize * 50;  // Ajusté à la hauteur de la grille
				var margin = { top: 20, right: 20, bottom: 40, left: 50 };

				// Positionnement du graphique
				var chartX = gridSize * 50 + 50;
				var chartY = 20;

				// Supprime l'ancien graphique s'il existe
				svg.selectAll(".bar-chart-group").remove();

				// Création du groupe principal
				var chartGroup = svg.append("g")
					.attr("class", "bar-chart-group")
					.attr("transform", `translate(${chartX}, ${chartY})`);

				// Transformation des données en tableau
				var data = Object.keys(actionValues).map(action => ({
					action: action,
					value: actionValues[action]
				}));

				// Détermination des bornes pour gérer les valeurs négatives
				var minValue = d3.min(data, d => d.value);
				var maxValue = d3.max(data, d => d.value);

				// Création des échelles
				var x = d3.scaleBand()
					.domain(data.map(d => d.action))
					.range([0, chartWidth])
					.padding(0.2);

				var y = d3.scaleLinear()
					.domain([Math.min(0, minValue), Math.max(0, maxValue)]) // S'assure d'inclure 0
					.range([chartHeight - margin.bottom, margin.top]);

				var zeroY = y(0); // Position verticale de l'axe zéro

				// Ajout des barres
				chartGroup.selectAll("rect")
					.data(data)
					.enter()
					.append("rect")
					.attr("x", d => x(d.action))
					.attr("y", d => d.value >= 0 ? y(d.value) : zeroY) // Position en fonction du signe
					.attr("width", x.bandwidth())
					.attr("height", d => Math.abs(y(d.value) - zeroY)) // Hauteur proportionnelle
					.attr("fill", d => d.value >= 0 ? "steelblue" : "tomato"); // Couleur différente pour les négatifs

				// Ajout d'une ligne horizontale pour l'axe 0
				chartGroup.append("line")
					.attr("x1", 0)
					.attr("x2", chartWidth)
					.attr("y1", zeroY)
					.attr("y2", zeroY)
					.attr("stroke", "black")
					.attr("stroke-width", 1);

				// Ajout des labels de valeurs sur les barres
				chartGroup.selectAll("text.value-label")
					.data(data)
					.enter()
					.append("text")
					.attr("class", "value-label")
					.attr("x", d => x(d.action) + x.bandwidth() / 2)
					.attr("y", d => d.value >= 0 ? y(d.value) - 5 : y(d.value) + 15) // Ajustement selon le signe
					.attr("text-anchor", "middle")
					.attr("font-size", "13px")
					.attr("fill", "black")
					.text(d => d.value.toFixed(2));

				// Ajout des axes
				chartGroup.append("g")
					.attr("transform", `translate(0,${zeroY})`) // Position ajustée
					.call(d3.axisBottom(x));

				chartGroup.append("g")
					.call(d3.axisLeft(y));

			}
			else {
				svg.selectAll(".bar-chart-group").remove();
			}
		}

		function intToArrow(val) {
			// 0 gauche
			// 1 haut
			// 2 bas
			// 3 droite
			switch (val) {
				case 1: return "Haut";
				case 2: return "Bas";
				case 0: return "Gauche";
				case 3: return "Droite";
				default: return "?";
			}
		}

		var drawGrid = function () {
			var gh = env.gh; // height in cells
			var gw = env.gw; // width in cells
			var gs = env.gs; // total number of cells

			var sx = env.stox(state);
			var sy = env.stoy(state);
			d3.select('#cpos')
				.attr('cx', sx * cs + cs / 2)
				.attr('cy', sy * cs + cs / 2);

			// updates the grid with current state of world/agent
			for (var y = 0; y < gh; y++) {
				for (var x = 0; x < gw; x++) {
					var xcoord = x * cs;
					var ycoord = y * cs;
					var r = 255, g = 255, b = 255;
					var s = env.xytos(x, y);

					// get value of state s under agent policy
					if (typeof agent.V !== 'undefined') {
						var vv = agent.V[s];
					} else if (typeof agent.Q !== 'undefined') {
						var poss = env.allowedActions(s);
						var vv = -1;
						// get the max qvalue of every actions in that state
						for (var i = 0, n = poss.length; i < n; i++) {
							var qsa = agent.Q[poss[i] * gs + s];
							if (i === 0 || qsa > vv) { vv = qsa; }
						}
					}

					var ms = 100;
					if (vv > 0) { g = 255; r = 255 - vv * ms; b = 255 - vv * ms; }
					if (vv < 0) { g = 255 + vv * ms; r = 255; b = 255 + vv * ms; }
					var vcol = 'rgb(' + Math.floor(r) + ',' + Math.floor(g) + ',' + Math.floor(b) + ')';
					if (env.T[s] === 1) { vcol = "#AAA"; rcol = "#AAA"; }

					// update colors of rectangles based on value
					var r = rs[s];
					if (s === selected) {
						// highlight selected cell
						r.attr('fill', '#FF0');
					} else {
						r.attr('fill', vcol);
					}

					// write reward texts
					var rv = env.Rarr[s];
					var tr = trs[s];
					if (rv !== 0) {
						tr.text('R ' + rv.toFixed(1))
					}

					// skip rest for cliff
					if (env.T[s] === 1) continue;

					// write value
					var tv = tvs[s];
					if (s !== env.finalState)
						tv.text(String(Math.round(vv * 100) / 100)); // vv.toFixed(2)
					else
						tv.text("Objectif");

					// update policy arrows
					var paa = pas[s];
					for (var a = 0; a < 4; a++) {
						var pa = paa[a];
						var prob = agent.P[a * gs + s];
						if (prob < 0.01) { pa.attr('visibility', 'hidden'); }
						else { pa.attr('visibility', 'visible'); }
						var ss = cs / 2 * prob * 0.9;
						if (a === 0) { nx = -ss; ny = 0; }
						if (a === 1) { nx = 0; ny = -ss; }
						if (a === 2) { nx = 0; ny = ss; }
						if (a === 3) { nx = ss; ny = 0; }
						pa.attr('x1', xcoord + cs / 2)
							.attr('y1', ycoord + cs / 2)
							.attr('x2', xcoord + cs / 2 + nx)
							.attr('y2', ycoord + cs / 2 + ny);
					}
				}
			}
			if (barchart) {
				var qvalues = {};
				// 0 gauche
				// 1 haut
				// 2 bas
				// 3 droite
				if (typeof agent.Q !== 'undefined') {
					var poss = env.allowedActions(selectedCell);
					var vv = -1;
					// get the max qvalue of every actions in that state
					for (var i = 0, n = poss.length; i < n; i++) {
						var qsa = agent.Q[poss[i] * gs + selectedCell];
						var c = intToArrow(poss[i]);
						qvalues[c] = qsa;
					}
				}
				showBarChart(qvalues, d3.select('svg'), 6);
			}
		}

		var selected = -1;
		var cells = []

		var cellClicked = function (s) {
			var gs = env.gs; // total number of cells
			var qvalues = {};
			// 0 gauche
			// 1 haut
			// 2 bas
			// 3 droite
			if (typeof agent.Q !== 'undefined') {
				var poss = env.allowedActions(selectedCell);
				// get the max qvalue of every actions in that state
				for (var i = 0, n = poss.length; i < n; i++) {
					var qsa = agent.Q[poss[i] * gs + selectedCell];
					var c = intToArrow(poss[i]);
					qvalues[c] = qsa;
				}
			}
			if (s === selected && env.T[s] != 1) {
				selected = -1; // toggle off
				barchart = false;
				$("#rewardui").hide("slow", function () { });
				$(".qvaluescharts").hide("slow", function () { });
			} else if (env.T[s] != 1) {
				selected = s;
				selectedCell = s;
				barchart = true;
				$("#creward").html(env.Rarr[s].toFixed(2));
				$("#rewardui").show("slow", function () { });
				$(".qvaluescharts").show("slow", function () { });
				$("#rewardslider").slider('value', env.Rarr[s]);
			}
			showBarChart(qvalues, d3.select('svg'), 6);
			drawGrid(); // redraw
		}

		var nextStep = function () {
			flag = 1;
			equation = true;
			save_tick = steps_per_tick;
			steps_per_tick = 1;
			$("#startButton").html("Reprendre");
			sid = -1;
			tdlearn();
		}

		var startAgain = function () {
			if (flag === -1) {
				flag = 0;
				sid = 1;
			}
			else {
				for (var i = 0; i < Object.keys(rs).length; i++) {
					rs[i].attr("stroke", "#DEDEDE").attr("stroke-width", "2");
				}
				flag = -1;
				sid = -1;
			}
			tdlearn();
		}

		var steps_per_tick = 20;
		var save_tick = steps_per_tick;
		var flag = 0;
		var sid = -1;
		var nsteps_history = [];
		var nsteps_counter = 0;
		var nflot = 1000;
		var maxRew = 1.5;
		var minRew = 0;
		var previousState = -1;
		var tdlearn = function () {
			if (sid === -1) {
				sid = setInterval(function () {
					env.updateRewards();
					if (flag != 0) {
						if (flag > 0) {
							$("#startButton").html("Reprendre");
							flag -= 1;
						}
						else $("#startButton").html("Pause");
						for (var k = 0; k < steps_per_tick; k++) {
							var a = agent.act(state); // ask agent for an action
							var obs = env.sampleNextState(state, a); // run it through environment dynamics
							currentAction = a; // used for illustration on the equation
							currentQvalue = agent.Q[currentAction * env.gs + state];

							// to avoid processing the qvalues of the last state
							if (previousObs === undefined || !previousObs.reset_episode) {
								agent.learn(obs.r); // allow opportunity for the agent to learn
								nextStateReward = obs.r;

								previousState = state; // keep in mind the previous state
								state = obs.ns; // evolve environment to next state
								previousObs = obs;
								var vv = -1;
								var poss = env.allowedActions(state);
								// get the max qvalue of every actions in that state
								for (var i = 0, n = poss.length; i < n; i++) {
									var qsa = agent.Q[poss[i] * env.gs + state];
									if (i === 0 || qsa > vv) { vv = qsa; }
								}
								nextBestActionQvalue = vv;
								if (equation) {
									updateEquation(true);
									equation = false;
								}
							}
							else {
								previousObs = undefined;
							}
							nsteps_counter += 1;
							if (obs.reset_episode) {
								//----- fill the qvalues in the cells before printing on the plot
								for (var y = 0; y < env.gh; y++) {
									for (var x = 0; x < env.gw; x++) {
										var s = env.xytos(x, y);
										// get value of state s under agent policy
										if (typeof agent.Q !== 'undefined') {
											var poss = env.allowedActions(s);
											if (cells[s] === undefined)
												cells[s] = {}
											for (var i = 0; i < poss.length; i++) {
												if (cells[s][poss[i]] === undefined) {
													cells[s][poss[i]] = [];
												}
												cells[s][poss[i]].push(agent.Q[poss[i] * env.gs + s]);
											}
										}
									}
								}
								agent.resetEpisode();
								if (selectedCell >= 0) {
									if (nsteps_history.length >= nflot) {
										nsteps_history = nsteps_history.slice(1);
									}
									for (var i = 0; i < poss.length; i++) {
										if (cells[selectedCell][poss[i]] !== 'undefined' && cells[selectedCell][poss[i]].length >= nflot) {
											var poss = env.allowedActions(selectedCell);
											var size = cells[selectedCell][poss[i]].length;
											cells[selectedCell][poss[i]] = cells[selectedCell][poss[i]].slice(size - nflot, size);
										}
									}
								}
								nsteps_history.push(nsteps_counter);
								nsteps_counter = 0;
							}
						}
					}
					// keep track of reward history
					drawGrid(); // draw
				}, 20);
			} else {
				$("#startButton").html("Reprendre");
				flag = true;
				oneStep = false;
				steps_per_tick = save_tick;
				clearInterval(sid);
				sid = -1;
			}
		}

		function resetAgent() {
			eval($("#agentspec").val())
			agent = new RL.TDAgent(env, spec);
			$("#slider").slider('value', agent.epsilon);
			$("#gammaSlider").slider('value', agent.gamma);
			$("#alphaSlider").slider('value', agent.alpha);
			$("#speed").slider('value', steps_per_tick / 100);
			$("#spe").html((steps_per_tick / 100).toFixed(2));
			$("#eps").html(agent.epsilon.toFixed(2));
			state = env.startState(); // move state to beginning too
			drawGrid();
			updateEquation(false);
			for (var i = 0; i < Object.keys(rs).length; i++) {
				rs[i].attr("stroke", "#DEDEDE").attr("stroke-width", "2");
			}
		}

		function resetAll() {
			env.reset();
			agent.reset();
			drawGrid();
		}

		function initGraph() {
			var container = $("#flotreward");
			var containerQvaluesHaut = $("#flotqvalueshaut");
			var containerQvaluesBas = $("#flotqvaluesbas");
			var containerQvaluesGauche = $("#flotqvaluesgauche");
			var containerQvaluesDroite = $("#flotqvaluesdroite");
			var res = getFlotRewards();
			// 0 gauche
			// 1 haut
			// 2 bas
			// 3 droite
			var resQvaluesHaut = getflotqvalues(1);
			var resQvaluesBas = getflotqvalues(2);
			var resQvaluesGauche = getflotqvalues(0);
			var resQvaluesDroite = getflotqvalues(3);

			series = [{
				data: res,
				lines: { fill: true }
			}];
			var plot = $.plot(container, series, {
				grid: {
					borderWidth: 1,
					minBorderMargin: 20,
					labelMargin: 10,
					backgroundColor: {
						colors: ["#FFF", "#e4f4f4"]
					},
					margin: {
						top: 10,
						bottom: 10,
						left: 10,
					}
				},
				xaxis: {
					min: 0,
					max: nflot
				},
				yaxis: {
					min: 0,
					max: 500
				}
			});
			resQvaluesHaut = [{
				data: resQvaluesHaut,
				lines: { fill: true }
			}];
			resQvaluesBas = [{
				data: resQvaluesBas,
				lines: { fill: true }
			}];
			resQvaluesGauche = [{
				data: resQvaluesGauche,
				lines: { fill: true }
			}];
			resQvaluesDroite = [{
				data: resQvaluesDroite,
				lines: { fill: true }
			}];

			var options = {
				grid: {
					borderWidth: 1,
					minBorderMargin: 20,
					labelMargin: 10,
					backgroundColor: {
						colors: ["#FFF", "#e4f4f4"]
					},
					margin: {
						top: 10,
						bottom: 10,
						left: 10,
					}
				},
				xaxis: {
					min: 0,
					max: nflot
				},
				yaxis: {
					min: 0,
					max: 10
				}
			};
			var plotQvaluesHaut = $.plot(containerQvaluesHaut, resQvaluesHaut, options);
			var plotQvaluesBas = $.plot(containerQvaluesBas, resQvaluesBas, options);
			var plotQvaluesGauche = $.plot(containerQvaluesGauche, resQvaluesGauche, options);
			var plotQvaluesDroite = $.plot(containerQvaluesDroite, resQvaluesDroite, options);
			setInterval(function () {
				// 0 gauche
				// 1 haut
				// 2 bas
				// 3 droite
				resQvaluesHaut[0].data = getflotqvalues(1);
				resQvaluesBas[0].data = getflotqvalues(2);
				resQvaluesGauche[0].data = getflotqvalues(0);
				resQvaluesDroite[0].data = getflotqvalues(3);

				plotQvaluesHaut.setData(resQvaluesHaut);
				plotQvaluesBas.setData(resQvaluesBas);
				plotQvaluesGauche.setData(resQvaluesGauche);
				plotQvaluesDroite.setData(resQvaluesDroite);

				options.yaxis.max = Math.pow(maxRew + 1, 2);
				options.yaxis.min = Math.min(0, (minRew - 1) * 2);

				plotQvaluesHaut = $.plot(containerQvaluesHaut, resQvaluesHaut, options);
				plotQvaluesBas = $.plot(containerQvaluesBas, resQvaluesBas, options);
				plotQvaluesGauche = $.plot(containerQvaluesGauche, resQvaluesGauche, options);
				plotQvaluesDroite = $.plot(containerQvaluesDroite, resQvaluesDroite, options);

				plotQvaluesHaut.draw();
				plotQvaluesBas.draw();
				plotQvaluesGauche.draw();
				plotQvaluesDroite.draw();

				series[0].data = getFlotRewards();
				plot.setData(series);
				plot.draw();
			}, 100);
		}
		function getFlotRewards() {
			// zip rewards into flot data
			var res = [];
			for (var i = 0, n = nsteps_history.length; i < n; i++) {
				res.push([i, nsteps_history[i]]);
			}
			return res;
		}
		function getflotqvalues(direction) {
			// zip rewards into flot data
			var res = [];
			if (selectedCell >= 0 && cells[selectedCell] !== undefined) {
				var actions = Object.keys(cells[selectedCell]);
				var action = String(actions.find(function (value) {
					return value == String(direction);
				}));
				if (action >= 0) {
					for (var i = 0, n = cells[selectedCell][action].length; i < n; i++) {
						res.push([i, cells[selectedCell][action][i]]);
					}
				}
			}
			return res;
		}

		var state;
		var agent, env;
		function start() {
			env = new Gridworld(); // create environment
			state = env.startState();
			eval($("#agentspec").val())
			agent = new RL.TDAgent(env, spec);

			//agent = new RL.ActorCriticAgent(env, {'gamma':0.9, 'epsilon':0.2});

			// slider sets agent epsilon
			$("#slider").slider({
				min: 0,
				max: 1.01,
				value: agent.epsilon,
				step: 0.01,
				slide: function (event, ui) {
					agent.epsilon = ui.value;
					$("#eps").html(ui.value.toFixed(2));
				}
			});

			$("#gammaSlider").slider({
				min: 0,
				max: 1.01,
				value: agent.gamma,
				step: 0.01,
				slide: function (event, ui) {
					agent.gamma = ui.value;
					$("#gamma").html(ui.value.toFixed(2));
					updateEquation(false);
				}
			});

			$("#alphaSlider").slider({
				min: 0,
				max: 1.01,
				value: agent.alpha,
				step: 0.01,
				slide: function (event, ui) {
					agent.alpha = ui.value;
					$("#alpha").html(ui.value.toFixed(2));
					updateEquation(false);
				}
			});

			// slider sets expe speed
			$("#speed").slider({
				min: 0,
				max: 1.01,
				value: steps_per_tick / 100,
				step: 0.01,
				slide: function (event, ui) {
					steps_per_tick = ui.value * 100;
					save_tick = steps_per_tick;
					$("#spe").html(ui.value.toFixed(2));
				}
			});

			$("#rewardslider").slider({
				min: -5,
				max: 5.1,
				value: 0,
				step: 0.1,
				slide: function (event, ui) {
					if (selected >= 0) {
						env.Rarr[selected] = ui.value;
						$("#creward").html(ui.value.toFixed(2));
						drawGrid();
					}
				}
			});

			$("#eps").html(agent.epsilon.toFixed(2));
			$("#slider").slider('value', agent.epsilon);

			// render markdown
			$(".md").each(function () {
				$(this).html(marked($(this).html()));
			});

			initGrid();
			drawGrid();
			initGraph();
		}

		function updateEquation(updateColors) {
			let equationEl = document.getElementById("equation");
			var operation = Math.round((currentQvalue + agent.alpha * (nextStateReward + agent.gamma * nextBestActionQvalue - currentQvalue)) * 100) / 100;

			currentQvalue = Math.round(currentQvalue * 100) / 100;
			nextStateReward = Math.round(nextStateReward * 100) / 100;
			nextBestActionQvalue = Math.round(nextBestActionQvalue * 100) / 100;

			equationEl.innerHTML = `\\( ${operation} \\hspace{1cm} = \\hspace{1cm} \\textcolor{blueviolet}{${currentQvalue}} \\hspace{1cm} + 
			\\textcolor{orange}{${agent.alpha}} \\times [ \ \\textcolor{teal}{${nextStateReward}} \\hspace{0.5cm} + 
			\\textcolor{purple}{${agent.gamma}} \\times \\hspace{1.3cm} \\textcolor{blue}{${nextBestActionQvalue}} \\hspace{1.3cm} - 
			\\textcolor{blueviolet}{${currentQvalue}} ] \ \\)`;

			// Reset colors
			for (var i = 0; i < Object.keys(rs).length; i++) {
				rs[i].attr("stroke", "#DEDEDE").attr("stroke-width", "2");
			}
			if (updateColors && previousState >= 0) {
				rs[previousState].attr("stroke", "#B981EF").attr("stroke-width", "8px");
				rs[state].attr("stroke", "#1900FF").attr("stroke-width", "8px");
			}
			MathJax.typeset();
		}
	</script>
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
</head>

<body onload="start();">

	<!-- Page Content -->

	<div class="w3-teal container" id="wrap">
		<button class="w3-button w3-teal w3-xlarge" onclick="w3_open()">----------> ☰ Tutoriel <---------- </button>
		<div class="w3-container">
			<h1 style="text-align: center;">Temporal Difference QLearning Playground</h1>
		</div>
	</div>

	<div class="container" id="wrap" style="margin-top: 50px;">
		<div class="row" style="text-align: center;">
			<div class="col-sm-4">
				<button class="btn btn-danger" onclick="resetAgent()"
					style="width:150px;height:50px;margin-bottom:5px;">Reinitialiser agent</button>
			</div>
			<div class="col-sm-4">
				<button id="startButton" class="btn btn-primary" onclick="startAgain()"
					style="width:170px;height:50px;margin-bottom:5px;">Commencer</button>
			</div>
			<div class="col-sm-4">
				<button class="btn btn-success" onclick="nextStep()"
					style="width:150px;height:50px;margin-bottom:5px;">Prochaine
					étape</button>
			</div>
		</div>


		<br>
		<div class="row">
			<div class="col-sm-6">
				Vitesse de l'expérience : <span id="spe">0.20</span>
				<div id="speed" style="width: 100%;"></div>
			</div>
			<div class="col-sm-6">
				Exploration (epsilon) : <span id="eps">0.15</span>
				<div id="slider" style="width: 100%;"></div>
			</div>
		</div>


		<div class="row">
			<div id="draw" style="margin-top: 55px;"></div>

			<div id="rewardui">
				Récompense de la case : <span id="creward"></span>
				<div id="rewardslider"></div>
			</div>
		</div>
		<br>
		<div class="row">
			<h3>Équation utilisée pour mettre à jour les valeurs :</h3>
			<p style="font-size: 25px;">
				\( Q(s, a) \leftarrow \textcolor{blueviolet}{Q(s, a)} + \textcolor{orange}{\alpha} \times [ \,
				\textcolor{teal}{R_{t+1}} + \textcolor{purple}{\gamma} \times
				\textcolor{blue}{max_{a'}Q(s_{t+1}, a')} - \textcolor{blueviolet}{Q(s, a)} ]
				\, \)</p>
			<p id="equation" style="font-size: 25px;">
				\( Q(s, a) \leftarrow \textcolor{blueviolet}{Q(s, a)} + \textcolor{orange}{\alpha} \times [ \,
				\textcolor{teal}{R_{t+1}} + \textcolor{purple}{\gamma} \times
				\textcolor{blue}{max_{a'}Q(s_{t+1}, a')} - \textcolor{blueviolet}{Q(s, a)} ]
				\, \)</p>
		</div>
		<div class="row">
			<div class="col-sm-6">
				Taux d'apprentissage (alpha) : <span id="alpha">0.10</span>
				<div id="alphaSlider" style="width: 100%;"></div>
			</div>
			<div class="col-sm-6">
				Facteur de réduction (gamma) : <span id="gamma">0.9</span>
				<div id="gammaSlider" style="width: 100%;"></div>
			</div>
		</div>
		<div class="row qvaluescharts" style="margin-top: 25px;">
			<h3>Valeurs pour chaque action :</h3>
			<div class="col-sm-6">
				Gauche <div id="flotqvaluesgauche" style="width:400px; height: 150px;"></div>
			</div>
			<div class="col-sm-6">
				Droite <div id="flotqvaluesdroite" style="width:400px; height: 150px;"></div>
			</div>
		</div>
		<div class="row qvaluescharts" style="margin-top: 25px;">
			<div class="col-sm-6">
				Haut <div id="flotqvalueshaut" style="width:400px; height: 150px;"></div>
			</div>
			<div class="col-sm-6">
				Bas <div id="flotqvaluesbas" style="width:400px; height: 150px;"></div>
			</div>
		</div>

		<div class="row" style="margin-top: 25px;">
			<h3>Nombre d'actions pour atteindre l'objectif :</h3>
			<div id="flotreward" style="width:100%; height: 250px;"></div>
		</div>
	</div>

	<div class="w3-sidebar w3-bar-block w3-border-right"
		style="display:none; width: 28%; position: absolute; top:0px; left:0px" id="mySidebar">
		<button onclick="w3_close()" class="w3-bar-item w3-large">Fermer &times;</button>
		<h2>Bienvenue dans ce bac à sable</h2>
		<p style="font-size: 18px; margin: 15px;">
			Ici vous pourrez expérimenter le QLearning et essayer de changer ses paramètres pour mieux comprendre
			comment il fonctionne.
		</p>
		<h2>Introduction au Q-Learning</h2>
		<p style="font-size: 18px; margin: 15px;">
			Considérons un système quelconque : par exemple, un jeu vidéo dans lequel un robot doit s'évader d'un
			labyrinthe. Un agent (programme informatique, robot) doit alors
			apprendre à réaliser une tâche : gagner une partie de jeu vidéo avec le plus de points, s'évader d'un
			labyrinthe le plus rapidement possible. Le Q-learning permet
			d'apprendre une stratégie, qui indique quelle action effectuer dans chaque état du système. Par exemple, le
			robot peut apprendre d'aller à droite quand il se trouve sur la case (2, 3), mais d'aller en haut s'il se
			trouve sur la case (4, 6), etc. A chaque étape, l'agent reçoit une récompense immédiate qui est un nombre
			réel. Typiquement, l'agent peut recevoir 100 euros s'il est sorti du labyrinthe, ou s'il a gagné le jeu.
			L'agent perd 1 euro pour chaque pas de temps qu'il reste dans le labyrinthe. C'est le concepteur de
			l'environnement qui choisit ces récompenses immédiates lorsqu'il modélise le système.
		</p>
		<h2>Apprentissage</h2>
		<p style="font-size: 18px; margin: 15px;">
			L'apprentissage est réalisé grâce à une succession d'actions pendant lesquelles l'agent enregistre leur
			utilité. Plus une action a une utilité élevée (une qvalue élevée), plus il l'utilisera à l'avenir. <br>
			Les qvalues sont calculées grâce à l'équation suivante :
			<br>
			<br>
			\( Q(s, a) \leftarrow Q(s, a) + \alpha \times [ \, R_{t+1} + \gamma \times max_{a'}Q(s_{t+1}, a') - Q(s, a)
			] \)
			<br>
			<br>
			\( s \) : état actuel (case sur laquelle le point se trouve)<br>
			\( a \) : action choisie (gauche, droite, haut ou bas)<br>
			\( R \) : récompense obtenue après avoir pris l'action a <br>
			\( s' \) : nouvel état après l’action <br>
			\( max_{a'}Q(s',a') \) : meilleure valeur estimée dans l’état suivant s'<br>
			\( \alpha \) (taux d’apprentissage) : contrôle à quelle vitesse on met à jour Q(s,a)<br>
			\( \gamma \) (facteur de discount) : pondère l’importance des récompenses futures<br>
		</p>
		<h2>Exploration vs Exploitation</h2>
		<p style="font-size: 18px; margin: 15px;">
			L’agent doit trouver un équilibre entre :<br>

			- Exploiter ce qu’il sait déjà (choisir l’action avec la meilleure valeur \( Q(s,a) \)<br>
			- Explorer de nouvelles actions pour découvrir potentiellement de meilleures stratégies. L'exploration peut
			être réglée avec l'hyperparamètre \( epsilon \) qui est une probabilité que l’agent
			choisisse une action aléatoire (exploration).<br>
		</p>
		<h2>Comment utiliser ce bac à sable ?</h2>
		<p style="font-size: 18px; margin: 15px;">
			1. Cliquez sur le bouton "Commencer" et observez comment l'agent apprend à se diriger sur sa case
			objectif.<br>
			2. Cliquez sur une case du plateau pour voir la valeur de chaque action. Notez que l'agent utilise toujours
			l'action qui a la plus forte valeur, sauf s'il explore son environnement. Vous pouvez essayer plusieurs
			valeurs de \( epsilon \) pour et voir comment l'agent se comporte.<br>
			3. Cliquez sur la case objectif et changez la valeur de la récompense associée en une valeur négative.
			Cliquez ensuite sur les cases adjacentes et observez les graphique de qvalues de chaque action. La stratégie
			de l'agent s'adapte aux récompenses de la grille.<br>
			4. Modifiez la valeur de \( alpha \) à 0. Que se passe-t-il ? Modifiez là en 1. Et à présent ?<br>
			5. Modifiez la valeur de \( gamma \) à 0. Que se passe-t-il ? Modifiez là en 1. Et à présent ?<br>
			6. Cliquez sur le bouton "Prochaine étape". Vous voyez apparaître les valeurs de chaque terme dans
			l'équation de mise à jour des valeurs. Observez chaque terme, vous pourrez voir que la qvaleur d'un couple
			(état, action) est "tirée" par la valeur maximum du prochain état.<br>
			7. Enfin, essayez de jouer avec tous les paramètres dubac à sable pour essayer de minimiser le nombre
			d'actions effectuées pour aller du départ à l'objectif. Vous pourrez visualiser votre avancement avec le
			dernier graphique.<br>
			<!DOCTYPE html>
			<html lang="en">

			<head>
				<meta charset="UTF-8">
				<meta name="viewport" content="width=device-width, initial-scale=1.0">
				<title>Document</title>
			</head>

			<body>

			</body>

			</html>
		</p>

	</div>
	<script>
		function w3_open() {
			document.getElementById("mySidebar").style.display = "block";
		}

		function w3_close() {
			document.getElementById("mySidebar").style.display = "none";
		}
	</script>
</body>

</html>